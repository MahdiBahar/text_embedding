{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25bb3c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mahdi/text_embedding/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model_name = \"hiieu/halong_embedding\"\n",
    "\n",
    "model = SentenceTransformer('hiieu/halong_embedding')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57e8a664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['anchor', 'positive', 'negetive'],\n",
      "    num_rows: 686\n",
      "})\n",
      "['anchor', 'positive', 'negetive']\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "ds = load_from_disk('APN_dataset')\n",
    "print(ds)                # see if it’s a Dataset or DatasetDict\n",
    "print(ds.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5580e0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'anchor': 'عقد مرابحه یک نوع عقد بانکی است که در آن بانک برای مبلغ وام\\u200cدهی، به برداشتن شخص قابل امتیاز تشخیص می\\u200cدهد که باید برای این مقدار دریافت شده چقدر سود بپردازد. این اطلاعات به صورت منظم و با روشنی تعیین می\\u200cشود، که نتیجه آن شفافیت در قرارداد است.', 'positive': 'عقد مرابحه چیست و آیا شفاف بودن قرارداد اصلی در این نوع عقد با اشاره به مبلغ سود است؟', 'negetive': 'چه نوع از وام\\u200cهای ازدواجی توصیه می\\u200cشود و آیا آن\\u200cها در این منبع تحت پوشش هستند؟'}\n",
      "{'anchor': 'بله، به نقطه تاس۱۰ توجه کنید: «امکان ضمانت متقابل انواع وام\\u200cها در بانک ملت وجود ندارد».', 'positive': 'آیا امکان ضمانت متقابل در وام\\u200cهای مختلف در بانک ملت وجود دارد؟', 'negetive': 'نحوه محاسبه توان بازپرداخت چگونه است؟'}\n",
      "{'anchor': 'قرض الحسنه یعنی وامی است که بدون سود و بهره داده می\\u200cشود و فقط اصل پول باید برگردانده شود.', 'positive': 'قرض الحسنه به معنای کدام نوع وام است؟', 'negetive': 'وام های ازدواج و فرزندآوری در طبقه\\u200cبندی معمول تکلیفی قرار می\\u200cگیرند یا نه؟'}\n",
      "{'anchor': 'وثیقه وثیقه، جسارت یا گنجینه\\u200cای است که شما به عنوان ضمانت به بانک میدید. این ماده به منظور تضمین پرداخت بدهی در صورت عدم وفاء باشندگان مالی، قابلیت استفاده دارد تا بانک خساراتی که از طرف شما به وجود آید جبران کند.', 'positive': 'وثیقه وثیقه در زمینه\\u200cای که شما به بانک میدهید به چه هدف داده می\\u200cشود؟', 'negetive': 'موقعیت فعلی نوشتار دوبله در پایگاه\\u200cداده وجود دارد؟'}\n",
      "{'anchor': 'امتیازی که فردی برای تسهیلات مالی خاص مانند دریافت وام با گردش حساب یا دستیابی به امتیازات معین\\u200cگیری کسب کرده است، به نزدیکان خود راه\\u200cانتقال داده شده تا آنان نیز از وام یا سایر تسهیلات با مشروطیت همچون کسب این امتیاز\\u200cها استفاده کنند.', 'positive': 'نحوه انتقال امتیاز به نزدیکان در ایران چگونه است؟', 'negetive': 'عواملی که بر توان بازپرداخت فرد تأثیر می\\u200cگذارند کدام هستند؟'}\n"
     ]
    }
   ],
   "source": [
    "# print first 5 examples\n",
    "for ex in ds.select(range(5)):\n",
    "    print(ex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71c66dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = ds.train_test_split(test_size=0.1, seed=42)\n",
    "train_ds = splits['train']\n",
    "dev_ds   = splits['test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cc1d21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Rename the typo’d column\n",
    "train_ds = train_ds.rename_column(\"negetive\", \"negative\")\n",
    "dev_ds   = dev_ds.rename_column(\"negetive\", \"negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab30cb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import InputExample\n",
    "\n",
    "# assume `train_ds` is your HF Dataset with columns ['anchor','positive','negative']\n",
    "\n",
    "train_examples = [\n",
    "    InputExample(\n",
    "        texts=[item['anchor'], item['positive'], item['negative']]\n",
    "    )\n",
    "    for item in train_ds  # iterates over all examples\n",
    "]\n",
    "\n",
    "# if you also split out dev_ds:\n",
    "dev_examples = [\n",
    "    InputExample(\n",
    "        texts=[item['anchor'], item['positive'], item['negative']]\n",
    "    )\n",
    "    for item in dev_ds\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d20d6c12",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 734.00 MiB. GPU 0 has a total capacity of 7.77 GiB of which 450.25 MiB is free. Process 229497 has 5.60 GiB memory in use. Including non-PyTorch memory, this process has 1.24 GiB memory in use. Of the allocated memory 1.04 GiB is allocated by PyTorch, and 55.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer, losses\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m model = \u001b[43mSentenceTransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhiieu/halong_embedding\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m train_loader = DataLoader(train_examples, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m, batch_size=\u001b[32m16\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# train_loss   = losses.TripletLoss(model=model)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/text_embedding/.venv/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py:348\u001b[39m, in \u001b[36mSentenceTransformer.__init__\u001b[39m\u001b[34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, similarity_fn_name, cache_folder, trust_remote_code, revision, local_files_only, token, use_auth_token, truncate_dim, model_kwargs, tokenizer_kwargs, config_kwargs, model_card_data, backend)\u001b[39m\n\u001b[32m    345\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    346\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m348\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[38;5;28mself\u001b[39m.is_hpu_graph_enabled = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.default_prompt_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.default_prompt_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.prompts:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/text_embedding/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1343\u001b[39m, in \u001b[36mModule.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1340\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1341\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/text_embedding/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:903\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    901\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    902\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m903\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    905\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    906\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    907\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    908\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    913\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    914\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/text_embedding/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:903\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    901\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    902\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m903\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    905\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    906\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    907\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    908\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    913\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    914\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[31m[... skipping similar frames: Module._apply at line 903 (1 times)]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/text_embedding/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:903\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    901\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    902\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m903\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    905\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    906\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    907\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    908\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    913\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    914\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/text_embedding/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:930\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    926\u001b[39m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[32m    927\u001b[39m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[32m    928\u001b[39m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[32m    929\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m930\u001b[39m     param_applied = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    931\u001b[39m p_should_use_set_data = compute_should_use_set_data(param, param_applied)\n\u001b[32m    933\u001b[39m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/text_embedding/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1329\u001b[39m, in \u001b[36mModule.to.<locals>.convert\u001b[39m\u001b[34m(t)\u001b[39m\n\u001b[32m   1322\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t.dim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m):\n\u001b[32m   1323\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m t.to(\n\u001b[32m   1324\u001b[39m             device,\n\u001b[32m   1325\u001b[39m             dtype \u001b[38;5;28;01mif\u001b[39;00m t.is_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t.is_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1326\u001b[39m             non_blocking,\n\u001b[32m   1327\u001b[39m             memory_format=convert_to_format,\n\u001b[32m   1328\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1329\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1330\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1331\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1332\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1333\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1334\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1335\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) == \u001b[33m\"\u001b[39m\u001b[33mCannot copy out of meta tensor; no data!\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 734.00 MiB. GPU 0 has a total capacity of 7.77 GiB of which 450.25 MiB is free. Process 229497 has 5.60 GiB memory in use. Including non-PyTorch memory, this process has 1.24 GiB memory in use. Of the allocated memory 1.04 GiB is allocated by PyTorch, and 55.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import SentenceTransformer, losses\n",
    "\n",
    "model = SentenceTransformer('hiieu/halong_embedding')\n",
    "\n",
    "train_loader = DataLoader(train_examples, shuffle=True, batch_size=16)\n",
    "# train_loss   = losses.TripletLoss(model=model)\n",
    "train_loss = losses.TripletLoss(\n",
    "    model=model,\n",
    "    triplet_margin=0.5,               # you can tune this margin\n",
    "    distance_metric=losses.SiameseDistanceMetric.COSINE\n",
    ")\n",
    "# (optional) set up a triplet evaluator on dev_examples, or skip if you don’t have one\n",
    "# from sentence_transformers.evaluation import TripletEvaluator\n",
    "# triplet_evaluator = TripletEvaluator.from_input_examples(dev_examples, name='persian-triplet')\n",
    "\n",
    "model.fit(\n",
    "    train_objectives=[(train_loader, train_loss)],\n",
    "    epochs=3,\n",
    "    warmup_steps=100,\n",
    "    # evaluator=triplet_evaluator,\n",
    "    # evaluation_steps=len(train_loader),\n",
    "    output_path='./halong_persian_triplet'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe2280d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
